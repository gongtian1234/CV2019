{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d4RsIz0BPYJr"
   },
   "outputs": [],
   "source": [
    " %tensorflow_version 1.x\n",
    "import tensorflow as tf\n",
    "from keras.applications import inception_v3\n",
    "from keras.layers import Dense, Flatten, Activation, Dropout\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lAqxnheuPaiY"
   },
   "outputs": [],
   "source": [
    "inceptionv3_model = inception_v3.InceptionV3(include_top=False, weights='imagenet', input_shape=(224,224,3),\n",
    "                                            classes=2)\n",
    "x = inceptionv3_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(units=256, activation='relu', name='fc1', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(rate=0.2)(x)\n",
    "predictions = Dense(units=2, activation='softmax')(x)\n",
    "model = Model(inputs=inceptionv3_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "4bv-tIHqPy24",
    "outputId": "d6723e1c-c2b5-40b8-d009-335466750080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n",
      "{'cat': 0, 'dog': 1}\n"
     ]
    }
   ],
   "source": [
    "# 图像增强\n",
    "train_datagen = image.ImageDataGenerator()\n",
    "val_datagen = image.ImageDataGenerator()\n",
    "\n",
    "batch_size= 32\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './image/train',\n",
    "    target_size=(224,224),batch_size=batch_size\n",
    "                                                   )\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    './image/test',\n",
    "    target_size=(224,224),batch_size=batch_size\n",
    "                                               )\n",
    "\n",
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XLc8mq6ISJjz",
    "outputId": "a44b88e7-d749-4760-9c00-bfe1fd50d609"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/201\n",
      "13/13 [==============================] - 31s 2s/step - loss: 0.7876 - acc: 0.5694 - val_loss: 0.5146 - val_acc: 0.7600\n",
      "Epoch 2/201\n",
      "13/13 [==============================] - 10s 777ms/step - loss: 0.3714 - acc: 0.8463 - val_loss: 0.3447 - val_acc: 0.8600\n",
      "Epoch 3/201\n",
      "13/13 [==============================] - 10s 776ms/step - loss: 0.1905 - acc: 0.9351 - val_loss: 0.2950 - val_acc: 0.8850\n",
      "Epoch 4/201\n",
      "13/13 [==============================] - 10s 780ms/step - loss: 0.1330 - acc: 0.9662 - val_loss: 0.2708 - val_acc: 0.8900\n",
      "Epoch 5/201\n",
      "13/13 [==============================] - 10s 779ms/step - loss: 0.0894 - acc: 0.9831 - val_loss: 0.2628 - val_acc: 0.9050\n",
      "Epoch 6/201\n",
      "13/13 [==============================] - 10s 785ms/step - loss: 0.0907 - acc: 0.9788 - val_loss: 0.2672 - val_acc: 0.9000\n",
      "Epoch 7/201\n",
      "13/13 [==============================] - 10s 780ms/step - loss: 0.0643 - acc: 0.9879 - val_loss: 0.2589 - val_acc: 0.9050\n",
      "Epoch 8/201\n",
      "13/13 [==============================] - 10s 779ms/step - loss: 0.0551 - acc: 0.9905 - val_loss: 0.2466 - val_acc: 0.9000\n",
      "Epoch 9/201\n",
      "13/13 [==============================] - 10s 780ms/step - loss: 0.0544 - acc: 0.9904 - val_loss: 0.2473 - val_acc: 0.9200\n",
      "Epoch 10/201\n",
      "13/13 [==============================] - 10s 783ms/step - loss: 0.0293 - acc: 1.0000 - val_loss: 0.2454 - val_acc: 0.9150\n",
      "Epoch 11/201\n",
      "13/13 [==============================] - 10s 781ms/step - loss: 0.0275 - acc: 0.9954 - val_loss: 0.2415 - val_acc: 0.9100\n",
      "Epoch 12/201\n",
      "13/13 [==============================] - 10s 779ms/step - loss: 0.0269 - acc: 1.0000 - val_loss: 0.2414 - val_acc: 0.9100\n",
      "Epoch 13/201\n",
      "13/13 [==============================] - 10s 780ms/step - loss: 0.0285 - acc: 0.9976 - val_loss: 0.2412 - val_acc: 0.9150\n",
      "Epoch 14/201\n",
      "13/13 [==============================] - 10s 779ms/step - loss: 0.0216 - acc: 0.9929 - val_loss: 0.2399 - val_acc: 0.9100\n",
      "Epoch 15/201\n",
      "13/13 [==============================] - 10s 779ms/step - loss: 0.0273 - acc: 0.9952 - val_loss: 0.2395 - val_acc: 0.9200\n",
      "Epoch 16/201\n",
      "13/13 [==============================] - 10s 780ms/step - loss: 0.0252 - acc: 0.9952 - val_loss: 0.2401 - val_acc: 0.9200\n",
      "Epoch 17/201\n",
      "13/13 [==============================] - 10s 779ms/step - loss: 0.0388 - acc: 0.9861 - val_loss: 0.2596 - val_acc: 0.9100\n",
      "Epoch 18/201\n",
      "13/13 [==============================] - 10s 781ms/step - loss: 0.0198 - acc: 1.0000 - val_loss: 0.2374 - val_acc: 0.9200\n",
      "Epoch 19/201\n",
      "13/13 [==============================] - 10s 781ms/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.2440 - val_acc: 0.9150\n",
      "Epoch 20/201\n",
      "13/13 [==============================] - 10s 784ms/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.2465 - val_acc: 0.9100\n",
      "Epoch 21/201\n",
      "13/13 [==============================] - 10s 782ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.2386 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 22/201\n",
      "13/13 [==============================] - 10s 789ms/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.2373 - val_acc: 0.9150\n",
      "Epoch 23/201\n",
      "13/13 [==============================] - 10s 780ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.2367 - val_acc: 0.9150\n",
      "Epoch 24/201\n",
      "13/13 [==============================] - 10s 777ms/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.2362 - val_acc: 0.9150\n",
      "Epoch 25/201\n",
      "13/13 [==============================] - 10s 782ms/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.2366 - val_acc: 0.9150\n",
      "Epoch 26/201\n",
      "13/13 [==============================] - 10s 779ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.2367 - val_acc: 0.9150\n",
      "Epoch 27/201\n",
      "13/13 [==============================] - 10s 781ms/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.2361 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 28/201\n",
      "13/13 [==============================] - 10s 780ms/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.2360 - val_acc: 0.9150\n",
      "Epoch 29/201\n",
      "13/13 [==============================] - 10s 782ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.2354 - val_acc: 0.9150\n",
      "Epoch 30/201\n",
      "13/13 [==============================] - 10s 782ms/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.2350 - val_acc: 0.9150\n",
      "Epoch 31/201\n",
      "13/13 [==============================] - 10s 779ms/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.2342 - val_acc: 0.9150\n",
      "Epoch 32/201\n",
      "13/13 [==============================] - 10s 782ms/step - loss: 0.0147 - acc: 0.9976 - val_loss: 0.2341 - val_acc: 0.9150\n",
      "Epoch 33/201\n",
      "13/13 [==============================] - 10s 783ms/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.2344 - val_acc: 0.9150\n",
      "Epoch 34/201\n",
      "13/13 [==============================] - 10s 779ms/step - loss: 0.0137 - acc: 0.9952 - val_loss: 0.2344 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "Epoch 35/201\n",
      "13/13 [==============================] - 10s 779ms/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.2347 - val_acc: 0.9150\n",
      "Epoch 36/201\n",
      "13/13 [==============================] - 10s 781ms/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.2355 - val_acc: 0.9150\n",
      "Epoch 37/201\n",
      "13/13 [==============================] - 10s 783ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.2355 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "Epoch 38/201\n",
      "13/13 [==============================] - 10s 782ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.2355 - val_acc: 0.9150\n",
      "Epoch 39/201\n",
      "13/13 [==============================] - 10s 784ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.2355 - val_acc: 0.9150\n",
      "Epoch 40/201\n",
      "13/13 [==============================] - 10s 783ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.2356 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 41/201\n",
      "13/13 [==============================] - 10s 780ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.2357 - val_acc: 0.9150\n",
      "Epoch 00041: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0461fd9ba8>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystopping = EarlyStopping(monitor='val_loss', patience=9, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1,\n",
    "                             factor=0.2, mode='auto', min_delta=0.0001, min_lr=1e-7)\n",
    "model.compile(optimizer=SGD(lr=0.0001,momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_generator, steps_per_epoch=len(train_generator), epochs=201, validation_data=val_generator, \n",
    "                    validation_steps=len(val_generator),callbacks=[earlystopping,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bDGJF9ZHaDmW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "04inceptionv3_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
