{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention_56.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvZrTAbDcg1Z",
        "colab_type": "code",
        "outputId": "22276f6f-bea6-4e1d-af05-4bdbdab3388c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub6LrCTucgTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/model_train/09 论文精读模型文件/03 ResNet50')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5dIn079bQCj",
        "colab_type": "code",
        "outputId": "310da011-7b73-4068-f30f-0c2e37d2fc3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "from keras.layers import Input, Multiply,GlobalAveragePooling2D, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Lambda\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.optimizers import SGD,Adam\n",
        "#import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "#from resnets_utils import *\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3URWmGtkbQCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def res_conv(X, filters, base, s):\n",
        "    \n",
        "    name_base = base + '/branch'\n",
        "    \n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    ##### Branch1 is the main path and Branch2 is the shortcut path #####\n",
        "    \n",
        "    X_shortcut = X\n",
        "    \n",
        "    ##### Branch1 #####\n",
        "    # First component of Branch1 \n",
        "    X = BatchNormalization(axis=-1, name=name_base + '1/bn_1')(X)\n",
        "    X= Activation('relu', name=name_base + '1/relu_1')(X)\n",
        "    X = Conv2D(filters=F1, kernel_size=(1,1), strides=(1,1), padding='valid', name=name_base + '1/conv_1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "\n",
        "    # Second component of Branch1\n",
        "    X = BatchNormalization(axis=-1, name=name_base + '1/bn_2')(X)\n",
        "    X = Activation('relu', name=name_base + '1/relu_2')(X)\n",
        "    X = Conv2D(filters=F2, kernel_size=(3,3), strides=(s,s), padding='same', name=name_base + '1/conv_2', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    # Third component of Branch1\n",
        "    X = BatchNormalization(axis=-1, name=name_base + '1/bn_3')(X)\n",
        "    X = Activation('relu', name=name_base + '1/relu_3')(X)\n",
        "    X = Conv2D(filters=F3, kernel_size=(1,1), strides=(1,1), padding='valid', name=name_base + '1/conv_3', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    ##### Branch2 ####\n",
        "    X_shortcut = BatchNormalization(axis=-1, name=name_base + '2/bn_1')(X_shortcut)\n",
        "    X_shortcut= Activation('relu', name=name_base + '2/relu_1')(X_shortcut)\n",
        "    X_shortcut = Conv2D(filters=F3, kernel_size=(1,1), strides=(s,s), padding='valid', name=name_base + '2/conv_1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
        "    \n",
        "    # Final step: Add Branch1 and Branch2\n",
        "    X = Add(name=base + '/Add')([X, X_shortcut])\n",
        "\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSBxMw4bbQCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def res_identity(X, filters, base):\n",
        "    \n",
        "    name_base = base + '/branch'\n",
        "    \n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    ##### Branch1 is the main path and Branch2 is the shortcut path #####\n",
        "    \n",
        "    X_shortcut = X\n",
        "    \n",
        "    ##### Branch1 #####\n",
        "    # First component of Branch1 \n",
        "    X = BatchNormalization(axis=-1, name=name_base + '1/bn_1')(X)\n",
        "    Shortcut= Activation('relu', name=name_base + '1/relu_1')(X)\n",
        "    X = Conv2D(filters=F1, kernel_size=(1,1), strides=(1,1), padding='valid', name=name_base + '1/conv_1', kernel_initializer=glorot_uniform(seed=0))(Shortcut)\n",
        "\n",
        "    # Second component of Branch1\n",
        "    X = BatchNormalization(axis=-1, name=name_base + '1/bn_2')(X)\n",
        "    X = Activation('relu', name=name_base + '1/relu_2')(X)\n",
        "    X = Conv2D(filters=F2, kernel_size=(3,3), strides=(1,1), padding='same', name=name_base + '1/conv_2', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    # Third component of Branch1\n",
        "    X = BatchNormalization(axis=-1, name=name_base + '1/bn_3')(X)\n",
        "    X = Activation('relu', name=name_base + '1/relu_3')(X)\n",
        "    X = Conv2D(filters=F3, kernel_size=(1,1), strides=(1,1), padding='valid', name=name_base + '1/conv_3', kernel_initializer=glorot_uniform(seed=0))(X)    \n",
        "    \n",
        "    # Final step: Add Branch1 and the original Input itself\n",
        "    X = Add(name=base + '/Add')([X, X_shortcut])\n",
        "\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GECKlbCXbQCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Trunk_block(X, F, base):\n",
        "    \n",
        "    name_base = base\n",
        "    \n",
        "    X = res_identity(X, F, name_base + '/Residual_id_1')\n",
        "    X = res_identity(X, F, name_base + '/Residual_id_2')\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7TFD7Mb9bVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def interpolation(input_tensor, ref_tensor,name): # resizes input_tensor wrt. ref_tensor\n",
        "    H, W = ref_tensor.get_shape()[1], ref_tensor.get_shape()[2]\n",
        "    return tf.image.resize_nearest_neighbor(input_tensor, [H.value, W.value],name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXak_q7_bQCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Attention_1(X, filters, base):\n",
        "    \n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    name_base = base\n",
        "    \n",
        "    X = res_identity(X, filters, name_base+ '/Pre_Residual_id')\n",
        "    \n",
        "    X_Trunk = Trunk_block(X, filters, name_base+ '/Trunk')\n",
        "    \n",
        "    X = MaxPooling2D((3,3), strides=(2,2), padding='same', name=name_base+ '/Mask/pool_3')(X)\n",
        "    \n",
        "    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_3_Down')\n",
        "    \n",
        "    Residual_id_3_Down_shortcut = X\n",
        "    \n",
        "    Residual_id_3_Down_branched = res_identity(X, filters, name_base+ '/Mask/Residual_id_3_Down_branched')\n",
        "    \n",
        "    X = MaxPooling2D((3,3), strides=(2,2), padding='same', name=name_base+ '/Mask/pool_2')(X)\n",
        "    \n",
        "    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_2_Down')\n",
        "    \n",
        "    Residual_id_2_Down_shortcut = X\n",
        "    \n",
        "    Residual_id_2_Down_branched = res_identity(X, filters, name_base+ '/Mask/Residual_id_2_Down_branched')\n",
        "    \n",
        "    X = MaxPooling2D((3,3), strides=(2,2), padding='same', name=name_base+ '/Mask/pool_1')(X)\n",
        "    \n",
        "    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_1_Down')\n",
        "    \n",
        "    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_1_Up')\n",
        "    \n",
        "    temp_name1 = name_base+ \"/Mask/Interpool_1\"\n",
        "    \n",
        "    X = Lambda(interpolation, arguments={'ref_tensor': Residual_id_2_Down_shortcut,'name':temp_name1})(X)\n",
        "                                          \n",
        "    X = Add(name=base + '/Mask/Add_after_Interpool_1')([X, Residual_id_2_Down_branched])\n",
        "                                          \n",
        "    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_2_Up')\n",
        "    \n",
        "    temp_name2 = name_base+ \"/Mask/Interpool_2\"\n",
        "    \n",
        "    X = Lambda(interpolation, arguments={'ref_tensor': Residual_id_3_Down_shortcut,'name':temp_name2})(X)\n",
        "                                          \n",
        "    X = Add(name=base + '/Mask/Add_after_Interpool_2')([X, Residual_id_3_Down_branched])\n",
        "                                          \n",
        "    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_3_Up')\n",
        "    \n",
        "    temp_name3 = name_base+ \"/Mask/Interpool_3\"\n",
        "    \n",
        "    X = Lambda(interpolation, arguments={'ref_tensor': X_Trunk,'name':temp_name3})(X)\n",
        "                                          \n",
        "    X = BatchNormalization(axis=-1, name=name_base + '/Mask/Interpool_3/bn_1')(X)\n",
        "                                          \n",
        "    X = Activation('relu', name=name_base + '/Mask/Interpool_3/relu_1')(X)\n",
        "                                          \n",
        "    X = Conv2D(F3, kernel_size=(1,1), strides=(1,1), padding='valid', name=name_base + '/Mask/Interpool_3/conv_1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    X = BatchNormalization(axis=-1, name=name_base + '/Mask/Interpool_3/bn_2')(X)\n",
        "                                          \n",
        "    X = Activation('relu', name=name_base + '/Mask/Interpool_3/relu_2')(X)\n",
        "                                          \n",
        "    X = Conv2D(F3, kernel_size=(1,1), strides=(1,1), padding='valid', name=name_base + '/Mask/Interpool_3/conv_2', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    X = Activation('sigmoid', name=name_base+'/Mask/sigmoid')(X)\n",
        "      \n",
        "    X = Multiply(name=name_base+'/Mutiply')([X_Trunk,X])\n",
        "    \n",
        "    X = Add(name=name_base+'/Add')([X_Trunk,X])\n",
        "\n",
        "    X = res_identity(X, filters, name_base+ '/Post_Residual_id')\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBBFhoUWX88_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Attention_2(X, filters, base):\n",
        "    \n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    name_base = base\n",
        "    \n",
        "    X = res_identity(X, filters, name_base+ '/Pre_Residual_id')\n",
        "    \n",
        "    X_Trunk = Trunk_block(X, filters, name_base+ '/Trunk')\n",
        "    \n",
        "    X = MaxPooling2D((3,3), strides=(2,2), padding='same', name=name_base+ '/Mask/pool_2')(X)\n",
        "    \n",
        "    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_2_Down')\n",
        "    \n",
        "    Residual_id_2_Down_shortcut = X\n",
        "    \n",
        "    Residual_id_2_Down_branched = res_identity(X, filters, name_base+ '/Mask/Residual_id_2_Down_branched')\n",
        "    \n",
        "    X = MaxPooling2D((3,3), strides=(2,2), padding='same', name=name_base+ '/Mask/pool_1')(X)\n",
        "    \n",
        "    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_1_Down')\n",
        "                                          \n",
        "    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_1_Up')\n",
        "    \n",
        "    temp_name1 = name_base+ \"/Mask/Interpool_1\"\n",
        "    \n",
        "    X = Lambda(interpolation, arguments={'ref_tensor': Residual_id_2_Down_shortcut,'name':temp_name1})(X)\n",
        "                                          \n",
        "    X = Add(name=base + '/Mask/Add_after_Interpool_1')([X, Residual_id_2_Down_branched])\n",
        "                                          \n",
        "    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_2_Up')\n",
        "    \n",
        "    temp_name2 = name_base+ \"/Mask/Interpool_2\"\n",
        "    \n",
        "    X = Lambda(interpolation, arguments={'ref_tensor': X_Trunk,'name':temp_name2})(X)\n",
        "                                          \n",
        "    X = BatchNormalization(axis=-1, name=name_base + '/Mask/Interpool_2/bn_1')(X)\n",
        "                                          \n",
        "    X = Activation('relu', name=name_base + '/Mask/Interpool_2/relu_1')(X)\n",
        "                                          \n",
        "    X = Conv2D(F3, kernel_size=(1,1), strides=(1,1), padding='valid', name=name_base + '/Mask/Interpool_2/conv_1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    X = BatchNormalization(axis=-1, name=name_base + '/Mask/Interpool_2/bn_2')(X)\n",
        "                                          \n",
        "    X = Activation('relu', name=name_base + '/Mask/Interpool_2/relu_2')(X)\n",
        "                                          \n",
        "    X = Conv2D(F3, kernel_size=(1,1), strides=(1,1), padding='valid', name=name_base + '/Mask/Interpool_2/conv_2', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    X = Activation('sigmoid', name=name_base+'/Mask/sigmoid')(X)\n",
        "      \n",
        "    X = Multiply(name=name_base+'/Mutiply')([X_Trunk,X])\n",
        "    \n",
        "    X = Add(name=name_base+'/Add')([X_Trunk,X])\n",
        "\n",
        "    X = res_identity(X, filters, name_base+ '/Post_Residual_id')\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GnVEAUGitAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Attention_3(X, filters, base):\n",
        "    \n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    name_base = base\n",
        "    \n",
        "    X = res_identity(X, filters, name_base+ '/Pre_Residual_id')\n",
        "    \n",
        "    X_Trunk = Trunk_block(X, filters, name_base+ '/Trunk')\n",
        "    \n",
        "    X = MaxPooling2D((3,3), strides=(2,2), padding='same', name=name_base+ '/Mask/pool_1')(X)\n",
        "    \n",
        "    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_1_Down')\n",
        "                                          \n",
        "    X = res_identity(X, filters, name_base+ '/Mask/Residual_id_1_Up')\n",
        "    \n",
        "    temp_name2 = name_base+ \"/Mask/Interpool_1\"\n",
        "    \n",
        "    X = Lambda(interpolation, arguments={'ref_tensor': X_Trunk,'name':temp_name2})(X)\n",
        "                                          \n",
        "    X = BatchNormalization(axis=-1, name=name_base + '/Mask/Interpool_2/bn_1')(X)\n",
        "                                          \n",
        "    X = Activation('relu', name=name_base + '/Mask/Interpool_2/relu_1')(X)\n",
        "                                          \n",
        "    X = Conv2D(F3, kernel_size=(1,1), strides=(1,1), padding='valid', name=name_base + '/Mask/Interpool_2/conv_1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    X = BatchNormalization(axis=-1, name=name_base + '/Mask/Interpool_2/bn_2')(X)\n",
        "                                          \n",
        "    X = Activation('relu', name=name_base + '/Mask/Interpool_2/relu_2')(X)\n",
        "                                          \n",
        "    X = Conv2D(F3, kernel_size=(1,1), strides=(1,1), padding='valid', name=name_base + '/Mask/Interpool_2/conv_2', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    X = Activation('sigmoid', name=name_base+'/Mask/sigmoid')(X)\n",
        "      \n",
        "    X = Multiply(name=name_base+'/Mutiply')([X_Trunk,X])\n",
        "    \n",
        "    X = Add(name=name_base+'/Add')([X_Trunk,X])\n",
        "\n",
        "    X = res_identity(X, filters, name_base+ '/Post_Residual_id')\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDTiXtMobQCz",
        "colab_type": "code",
        "outputId": "bde6bb6c-b1bc-4ada-bd3f-592c74d5c3db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "input_shape=(224, 224, 3)\n",
        "X_input = Input(input_shape)\n",
        "\n",
        "X = Conv2D(64, (7,7), strides=(2,2), padding='same', name='conv_1', kernel_initializer=glorot_uniform(seed=0))(X_input)\n",
        "X = BatchNormalization(axis=-1, name='bn_1')(X)\n",
        "X = Activation('relu', name='relu_1')(X)\n",
        "X = MaxPooling2D((3,3), strides=(2,2), padding='same' ,name='pool_1')(X)\n",
        "X = res_conv(X, [64,64,256], 'Residual_conv_1', 1)\n",
        "\n",
        "### Attention 1 Start\n",
        "X = Attention_1(X, [64,64,256], 'Attention_1')\n",
        "### Attention 1 End\n",
        "\n",
        "X = res_conv(X, [128,128,512], 'Residual_conv_2', 2)\n",
        "\n",
        "### Attention 2 Start\n",
        "X = Attention_2(X, [128,128,512], 'Attention_2')\n",
        "### Attention 2 End\n",
        "\n",
        "X = res_conv(X, [256,256,1024], 'Residual_conv_3', 2)\n",
        "\n",
        "### Attention 3 Start\n",
        "X = Attention_3(X, [256,256,1024], 'Attention_3')\n",
        "### Attention 3 End\n",
        "\n",
        "X = res_conv(X, [512,512,2048], 'Residual_conv_4', 2)\n",
        "\n",
        "X = res_identity(X, [512,512,2048], 'Residual_id_1')\n",
        "X = res_identity(X, [512,512,2048], 'Residual_id_2')\n",
        "X = BatchNormalization(axis=-1, name='bn_2')(X)\n",
        "X = Activation('relu', name='relu_2')(X)\n",
        "X = AveragePooling2D((7,7), strides=(1,1), name='avg_pool')(X)\n",
        "\n",
        "X = Flatten()(X)\n",
        "X = Dense(2, name='Dense_1')(X)\n",
        "\n",
        "# X = Dense(1000, name='Dense_1')(X)\n",
        "X = Activation('softmax', name='classifier')(X)\n",
        "model = Model(inputs=X_input, outputs=X, name='attention_56')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Model: \"attention_56\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_1 (Conv2D)                 (None, 112, 112, 64) 9472        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_1 (BatchNormalization)       (None, 112, 112, 64) 256         conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu_1 (Activation)             (None, 112, 112, 64) 0           bn_1[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "pool_1 (MaxPooling2D)           (None, 56, 56, 64)   0           relu_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_1/branch1/bn_1 (B (None, 56, 56, 64)   256         pool_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_1/branch1/relu_1  (None, 56, 56, 64)   0           Residual_conv_1/branch1/bn_1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_1/branch1/conv_1  (None, 56, 56, 64)   4160        Residual_conv_1/branch1/relu_1[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_1/branch1/bn_2 (B (None, 56, 56, 64)   256         Residual_conv_1/branch1/conv_1[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_1/branch1/relu_2  (None, 56, 56, 64)   0           Residual_conv_1/branch1/bn_2[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_1/branch1/conv_2  (None, 56, 56, 64)   36928       Residual_conv_1/branch1/relu_2[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_1/branch1/bn_3 (B (None, 56, 56, 64)   256         Residual_conv_1/branch1/conv_2[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_1/branch2/bn_1 (B (None, 56, 56, 64)   256         pool_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_1/branch1/relu_3  (None, 56, 56, 64)   0           Residual_conv_1/branch1/bn_3[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_1/branch2/relu_1  (None, 56, 56, 64)   0           Residual_conv_1/branch2/bn_1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_1/branch1/conv_3  (None, 56, 56, 256)  16640       Residual_conv_1/branch1/relu_3[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_1/branch2/conv_1  (None, 56, 56, 256)  16640       Residual_conv_1/branch2/relu_1[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_1/Add (Add)       (None, 56, 56, 256)  0           Residual_conv_1/branch1/conv_3[0]\n",
            "                                                                 Residual_conv_1/branch2/conv_1[0]\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Pre_Residual_id/bra (None, 56, 56, 256)  1024        Residual_conv_1/Add[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Pre_Residual_id/bra (None, 56, 56, 256)  0           Attention_1/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Pre_Residual_id/bra (None, 56, 56, 64)   16448       Attention_1/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Pre_Residual_id/bra (None, 56, 56, 64)   256         Attention_1/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Pre_Residual_id/bra (None, 56, 56, 64)   0           Attention_1/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Pre_Residual_id/bra (None, 56, 56, 64)   36928       Attention_1/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Pre_Residual_id/bra (None, 56, 56, 64)   256         Attention_1/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Pre_Residual_id/bra (None, 56, 56, 64)   0           Attention_1/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Pre_Residual_id/bra (None, 56, 56, 256)  16640       Attention_1/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Pre_Residual_id/Add (None, 56, 56, 256)  0           Attention_1/Pre_Residual_id/branc\n",
            "                                                                 Residual_conv_1/Add[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/pool_3 (MaxPoo (None, 28, 28, 256)  0           Attention_1/Pre_Residual_id/Add[0\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 256)  1024        Attention_1/Mask/pool_3[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 256)  0           Attention_1/Mask/Residual_id_3_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 64)   16448       Attention_1/Mask/Residual_id_3_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 64)   256         Attention_1/Mask/Residual_id_3_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 64)   0           Attention_1/Mask/Residual_id_3_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 64)   36928       Attention_1/Mask/Residual_id_3_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 64)   256         Attention_1/Mask/Residual_id_3_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 64)   0           Attention_1/Mask/Residual_id_3_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 256)  16640       Attention_1/Mask/Residual_id_3_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 256)  0           Attention_1/Mask/Residual_id_3_Do\n",
            "                                                                 Attention_1/Mask/pool_3[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/pool_2 (MaxPoo (None, 14, 14, 256)  0           Attention_1/Mask/Residual_id_3_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 256)  1024        Attention_1/Mask/pool_2[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 256)  0           Attention_1/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 64)   16448       Attention_1/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 64)   256         Attention_1/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 64)   0           Attention_1/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 64)   36928       Attention_1/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 64)   256         Attention_1/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 64)   0           Attention_1/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 256)  16640       Attention_1/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 256)  0           Attention_1/Mask/Residual_id_2_Do\n",
            "                                                                 Attention_1/Mask/pool_2[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/pool_1 (MaxPoo (None, 7, 7, 256)    0           Attention_1/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_1_ (None, 7, 7, 256)    1024        Attention_1/Mask/pool_1[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_1_ (None, 7, 7, 256)    0           Attention_1/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_1_ (None, 7, 7, 64)     16448       Attention_1/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_1_ (None, 7, 7, 64)     256         Attention_1/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_1_ (None, 7, 7, 64)     0           Attention_1/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_1_ (None, 7, 7, 64)     36928       Attention_1/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_1_ (None, 7, 7, 64)     256         Attention_1/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_1_ (None, 7, 7, 64)     0           Attention_1/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_1_ (None, 7, 7, 256)    16640       Attention_1/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_1_ (None, 7, 7, 256)    0           Attention_1/Mask/Residual_id_1_Do\n",
            "                                                                 Attention_1/Mask/pool_1[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_1_ (None, 7, 7, 256)    1024        Attention_1/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_1_ (None, 7, 7, 256)    0           Attention_1/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 256)  1024        Attention_1/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_1_ (None, 7, 7, 64)     16448       Attention_1/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 256)  0           Attention_1/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_1_ (None, 7, 7, 64)     256         Attention_1/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 64)   16448       Attention_1/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_1_ (None, 7, 7, 64)     0           Attention_1/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 64)   256         Attention_1/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_1_ (None, 7, 7, 64)     36928       Attention_1/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 64)   0           Attention_1/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_1_ (None, 7, 7, 64)     256         Attention_1/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 64)   36928       Attention_1/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_1_ (None, 7, 7, 64)     0           Attention_1/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 64)   256         Attention_1/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_1_ (None, 7, 7, 256)    16640       Attention_1/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 64)   0           Attention_1/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_1_ (None, 7, 7, 256)    0           Attention_1/Mask/Residual_id_1_Up\n",
            "                                                                 Attention_1/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 256)  16640       Attention_1/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 14, 14, 256)  0           Attention_1/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 256)  0           Attention_1/Mask/Residual_id_2_Do\n",
            "                                                                 Attention_1/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Add_after_Inte (None, 14, 14, 256)  0           lambda_1[0][0]                   \n",
            "                                                                 Attention_1/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 256)  1024        Attention_1/Mask/Add_after_Interp\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 256)  0           Attention_1/Mask/Residual_id_2_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 256)  1024        Attention_1/Mask/Residual_id_3_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 64)   16448       Attention_1/Mask/Residual_id_2_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 256)  0           Attention_1/Mask/Residual_id_3_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 64)   256         Attention_1/Mask/Residual_id_2_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 64)   16448       Attention_1/Mask/Residual_id_3_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 64)   0           Attention_1/Mask/Residual_id_2_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 64)   256         Attention_1/Mask/Residual_id_3_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 64)   36928       Attention_1/Mask/Residual_id_2_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 64)   0           Attention_1/Mask/Residual_id_3_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 64)   256         Attention_1/Mask/Residual_id_2_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 64)   36928       Attention_1/Mask/Residual_id_3_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 64)   0           Attention_1/Mask/Residual_id_2_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 64)   256         Attention_1/Mask/Residual_id_3_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 256)  16640       Attention_1/Mask/Residual_id_2_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 64)   0           Attention_1/Mask/Residual_id_3_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_2_ (None, 14, 14, 256)  0           Attention_1/Mask/Residual_id_2_Up\n",
            "                                                                 Attention_1/Mask/Add_after_Interp\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 256)  16640       Attention_1/Mask/Residual_id_3_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Trunk/Residual_id_1 (None, 56, 56, 256)  1024        Attention_1/Pre_Residual_id/Add[0\n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 28, 28, 256)  0           Attention_1/Mask/Residual_id_2_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 256)  0           Attention_1/Mask/Residual_id_3_Do\n",
            "                                                                 Attention_1/Mask/Residual_id_3_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Trunk/Residual_id_1 (None, 56, 56, 256)  0           Attention_1/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Add_after_Inte (None, 28, 28, 256)  0           lambda_2[0][0]                   \n",
            "                                                                 Attention_1/Mask/Residual_id_3_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Trunk/Residual_id_1 (None, 56, 56, 64)   16448       Attention_1/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 256)  1024        Attention_1/Mask/Add_after_Interp\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Trunk/Residual_id_1 (None, 56, 56, 64)   256         Attention_1/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 256)  0           Attention_1/Mask/Residual_id_3_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Trunk/Residual_id_1 (None, 56, 56, 64)   0           Attention_1/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 64)   16448       Attention_1/Mask/Residual_id_3_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Trunk/Residual_id_1 (None, 56, 56, 64)   36928       Attention_1/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 64)   256         Attention_1/Mask/Residual_id_3_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Trunk/Residual_id_1 (None, 56, 56, 64)   256         Attention_1/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 64)   0           Attention_1/Mask/Residual_id_3_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Trunk/Residual_id_1 (None, 56, 56, 64)   0           Attention_1/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 64)   36928       Attention_1/Mask/Residual_id_3_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Trunk/Residual_id_1 (None, 56, 56, 256)  16640       Attention_1/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 64)   256         Attention_1/Mask/Residual_id_3_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Trunk/Residual_id_1 (None, 56, 56, 256)  0           Attention_1/Trunk/Residual_id_1/b\n",
            "                                                                 Attention_1/Pre_Residual_id/Add[0\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 64)   0           Attention_1/Mask/Residual_id_3_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Trunk/Residual_id_2 (None, 56, 56, 256)  1024        Attention_1/Trunk/Residual_id_1/A\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 256)  16640       Attention_1/Mask/Residual_id_3_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Trunk/Residual_id_2 (None, 56, 56, 256)  0           Attention_1/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Residual_id_3_ (None, 28, 28, 256)  0           Attention_1/Mask/Residual_id_3_Up\n",
            "                                                                 Attention_1/Mask/Add_after_Interp\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Trunk/Residual_id_2 (None, 56, 56, 64)   16448       Attention_1/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 56, 56, 256)  0           Attention_1/Mask/Residual_id_3_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Trunk/Residual_id_2 (None, 56, 56, 64)   256         Attention_1/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Interpool_3/bn (None, 56, 56, 256)  1024        lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Trunk/Residual_id_2 (None, 56, 56, 64)   0           Attention_1/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Interpool_3/re (None, 56, 56, 256)  0           Attention_1/Mask/Interpool_3/bn_1\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Trunk/Residual_id_2 (None, 56, 56, 64)   36928       Attention_1/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Interpool_3/co (None, 56, 56, 256)  65792       Attention_1/Mask/Interpool_3/relu\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Trunk/Residual_id_2 (None, 56, 56, 64)   256         Attention_1/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Interpool_3/bn (None, 56, 56, 256)  1024        Attention_1/Mask/Interpool_3/conv\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Trunk/Residual_id_2 (None, 56, 56, 64)   0           Attention_1/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Interpool_3/re (None, 56, 56, 256)  0           Attention_1/Mask/Interpool_3/bn_2\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Trunk/Residual_id_2 (None, 56, 56, 256)  16640       Attention_1/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/Interpool_3/co (None, 56, 56, 256)  65792       Attention_1/Mask/Interpool_3/relu\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Trunk/Residual_id_2 (None, 56, 56, 256)  0           Attention_1/Trunk/Residual_id_2/b\n",
            "                                                                 Attention_1/Trunk/Residual_id_1/A\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mask/sigmoid (Activ (None, 56, 56, 256)  0           Attention_1/Mask/Interpool_3/conv\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Mutiply (Multiply)  (None, 56, 56, 256)  0           Attention_1/Trunk/Residual_id_2/A\n",
            "                                                                 Attention_1/Mask/sigmoid[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Add (Add)           (None, 56, 56, 256)  0           Attention_1/Trunk/Residual_id_2/A\n",
            "                                                                 Attention_1/Mutiply[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Post_Residual_id/br (None, 56, 56, 256)  1024        Attention_1/Add[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Post_Residual_id/br (None, 56, 56, 256)  0           Attention_1/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Post_Residual_id/br (None, 56, 56, 64)   16448       Attention_1/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Post_Residual_id/br (None, 56, 56, 64)   256         Attention_1/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Post_Residual_id/br (None, 56, 56, 64)   0           Attention_1/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Post_Residual_id/br (None, 56, 56, 64)   36928       Attention_1/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Post_Residual_id/br (None, 56, 56, 64)   256         Attention_1/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Post_Residual_id/br (None, 56, 56, 64)   0           Attention_1/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Post_Residual_id/br (None, 56, 56, 256)  16640       Attention_1/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_1/Post_Residual_id/Ad (None, 56, 56, 256)  0           Attention_1/Post_Residual_id/bran\n",
            "                                                                 Attention_1/Add[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_2/branch1/bn_1 (B (None, 56, 56, 256)  1024        Attention_1/Post_Residual_id/Add[\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_2/branch1/relu_1  (None, 56, 56, 256)  0           Residual_conv_2/branch1/bn_1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_2/branch1/conv_1  (None, 56, 56, 128)  32896       Residual_conv_2/branch1/relu_1[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_2/branch1/bn_2 (B (None, 56, 56, 128)  512         Residual_conv_2/branch1/conv_1[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_2/branch1/relu_2  (None, 56, 56, 128)  0           Residual_conv_2/branch1/bn_2[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_2/branch1/conv_2  (None, 28, 28, 128)  147584      Residual_conv_2/branch1/relu_2[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_2/branch1/bn_3 (B (None, 28, 28, 128)  512         Residual_conv_2/branch1/conv_2[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_2/branch2/bn_1 (B (None, 56, 56, 256)  1024        Attention_1/Post_Residual_id/Add[\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_2/branch1/relu_3  (None, 28, 28, 128)  0           Residual_conv_2/branch1/bn_3[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_2/branch2/relu_1  (None, 56, 56, 256)  0           Residual_conv_2/branch2/bn_1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_2/branch1/conv_3  (None, 28, 28, 512)  66048       Residual_conv_2/branch1/relu_3[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_2/branch2/conv_1  (None, 28, 28, 512)  131584      Residual_conv_2/branch2/relu_1[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_2/Add (Add)       (None, 28, 28, 512)  0           Residual_conv_2/branch1/conv_3[0]\n",
            "                                                                 Residual_conv_2/branch2/conv_1[0]\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Pre_Residual_id/bra (None, 28, 28, 512)  2048        Residual_conv_2/Add[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Pre_Residual_id/bra (None, 28, 28, 512)  0           Attention_2/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Pre_Residual_id/bra (None, 28, 28, 128)  65664       Attention_2/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Pre_Residual_id/bra (None, 28, 28, 128)  512         Attention_2/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Pre_Residual_id/bra (None, 28, 28, 128)  0           Attention_2/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Pre_Residual_id/bra (None, 28, 28, 128)  147584      Attention_2/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Pre_Residual_id/bra (None, 28, 28, 128)  512         Attention_2/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Pre_Residual_id/bra (None, 28, 28, 128)  0           Attention_2/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Pre_Residual_id/bra (None, 28, 28, 512)  66048       Attention_2/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Pre_Residual_id/Add (None, 28, 28, 512)  0           Attention_2/Pre_Residual_id/branc\n",
            "                                                                 Residual_conv_2/Add[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/pool_2 (MaxPoo (None, 14, 14, 512)  0           Attention_2/Pre_Residual_id/Add[0\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 512)  2048        Attention_2/Mask/pool_2[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 512)  0           Attention_2/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 128)  65664       Attention_2/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 128)  512         Attention_2/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 128)  0           Attention_2/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 128)  147584      Attention_2/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 128)  512         Attention_2/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 128)  0           Attention_2/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 512)  66048       Attention_2/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 512)  0           Attention_2/Mask/Residual_id_2_Do\n",
            "                                                                 Attention_2/Mask/pool_2[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/pool_1 (MaxPoo (None, 7, 7, 512)    0           Attention_2/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_1_ (None, 7, 7, 512)    2048        Attention_2/Mask/pool_1[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_1_ (None, 7, 7, 512)    0           Attention_2/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_1_ (None, 7, 7, 128)    65664       Attention_2/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_1_ (None, 7, 7, 128)    512         Attention_2/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_1_ (None, 7, 7, 128)    0           Attention_2/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_1_ (None, 7, 7, 128)    147584      Attention_2/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_1_ (None, 7, 7, 128)    512         Attention_2/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_1_ (None, 7, 7, 128)    0           Attention_2/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_1_ (None, 7, 7, 512)    66048       Attention_2/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_1_ (None, 7, 7, 512)    0           Attention_2/Mask/Residual_id_1_Do\n",
            "                                                                 Attention_2/Mask/pool_1[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_1_ (None, 7, 7, 512)    2048        Attention_2/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_1_ (None, 7, 7, 512)    0           Attention_2/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 512)  2048        Attention_2/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_1_ (None, 7, 7, 128)    65664       Attention_2/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 512)  0           Attention_2/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_1_ (None, 7, 7, 128)    512         Attention_2/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 128)  65664       Attention_2/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_1_ (None, 7, 7, 128)    0           Attention_2/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 128)  512         Attention_2/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_1_ (None, 7, 7, 128)    147584      Attention_2/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 128)  0           Attention_2/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_1_ (None, 7, 7, 128)    512         Attention_2/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 128)  147584      Attention_2/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_1_ (None, 7, 7, 128)    0           Attention_2/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 128)  512         Attention_2/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_1_ (None, 7, 7, 512)    66048       Attention_2/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 128)  0           Attention_2/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_1_ (None, 7, 7, 512)    0           Attention_2/Mask/Residual_id_1_Up\n",
            "                                                                 Attention_2/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 512)  66048       Attention_2/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Trunk/Residual_id_1 (None, 28, 28, 512)  2048        Attention_2/Pre_Residual_id/Add[0\n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 14, 14, 512)  0           Attention_2/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 512)  0           Attention_2/Mask/Residual_id_2_Do\n",
            "                                                                 Attention_2/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Trunk/Residual_id_1 (None, 28, 28, 512)  0           Attention_2/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Add_after_Inte (None, 14, 14, 512)  0           lambda_4[0][0]                   \n",
            "                                                                 Attention_2/Mask/Residual_id_2_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Trunk/Residual_id_1 (None, 28, 28, 128)  65664       Attention_2/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 512)  2048        Attention_2/Mask/Add_after_Interp\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Trunk/Residual_id_1 (None, 28, 28, 128)  512         Attention_2/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 512)  0           Attention_2/Mask/Residual_id_2_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Trunk/Residual_id_1 (None, 28, 28, 128)  0           Attention_2/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 128)  65664       Attention_2/Mask/Residual_id_2_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Trunk/Residual_id_1 (None, 28, 28, 128)  147584      Attention_2/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 128)  512         Attention_2/Mask/Residual_id_2_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Trunk/Residual_id_1 (None, 28, 28, 128)  512         Attention_2/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 128)  0           Attention_2/Mask/Residual_id_2_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Trunk/Residual_id_1 (None, 28, 28, 128)  0           Attention_2/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 128)  147584      Attention_2/Mask/Residual_id_2_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Trunk/Residual_id_1 (None, 28, 28, 512)  66048       Attention_2/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 128)  512         Attention_2/Mask/Residual_id_2_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Trunk/Residual_id_1 (None, 28, 28, 512)  0           Attention_2/Trunk/Residual_id_1/b\n",
            "                                                                 Attention_2/Pre_Residual_id/Add[0\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 128)  0           Attention_2/Mask/Residual_id_2_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Trunk/Residual_id_2 (None, 28, 28, 512)  2048        Attention_2/Trunk/Residual_id_1/A\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 512)  66048       Attention_2/Mask/Residual_id_2_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Trunk/Residual_id_2 (None, 28, 28, 512)  0           Attention_2/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Residual_id_2_ (None, 14, 14, 512)  0           Attention_2/Mask/Residual_id_2_Up\n",
            "                                                                 Attention_2/Mask/Add_after_Interp\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Trunk/Residual_id_2 (None, 28, 28, 128)  65664       Attention_2/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 28, 28, 512)  0           Attention_2/Mask/Residual_id_2_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Trunk/Residual_id_2 (None, 28, 28, 128)  512         Attention_2/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Interpool_2/bn (None, 28, 28, 512)  2048        lambda_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Trunk/Residual_id_2 (None, 28, 28, 128)  0           Attention_2/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Interpool_2/re (None, 28, 28, 512)  0           Attention_2/Mask/Interpool_2/bn_1\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Trunk/Residual_id_2 (None, 28, 28, 128)  147584      Attention_2/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Interpool_2/co (None, 28, 28, 512)  262656      Attention_2/Mask/Interpool_2/relu\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Trunk/Residual_id_2 (None, 28, 28, 128)  512         Attention_2/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Interpool_2/bn (None, 28, 28, 512)  2048        Attention_2/Mask/Interpool_2/conv\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Trunk/Residual_id_2 (None, 28, 28, 128)  0           Attention_2/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Interpool_2/re (None, 28, 28, 512)  0           Attention_2/Mask/Interpool_2/bn_2\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Trunk/Residual_id_2 (None, 28, 28, 512)  66048       Attention_2/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/Interpool_2/co (None, 28, 28, 512)  262656      Attention_2/Mask/Interpool_2/relu\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Trunk/Residual_id_2 (None, 28, 28, 512)  0           Attention_2/Trunk/Residual_id_2/b\n",
            "                                                                 Attention_2/Trunk/Residual_id_1/A\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mask/sigmoid (Activ (None, 28, 28, 512)  0           Attention_2/Mask/Interpool_2/conv\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Mutiply (Multiply)  (None, 28, 28, 512)  0           Attention_2/Trunk/Residual_id_2/A\n",
            "                                                                 Attention_2/Mask/sigmoid[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Add (Add)           (None, 28, 28, 512)  0           Attention_2/Trunk/Residual_id_2/A\n",
            "                                                                 Attention_2/Mutiply[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Post_Residual_id/br (None, 28, 28, 512)  2048        Attention_2/Add[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Post_Residual_id/br (None, 28, 28, 512)  0           Attention_2/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Post_Residual_id/br (None, 28, 28, 128)  65664       Attention_2/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Post_Residual_id/br (None, 28, 28, 128)  512         Attention_2/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Post_Residual_id/br (None, 28, 28, 128)  0           Attention_2/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Post_Residual_id/br (None, 28, 28, 128)  147584      Attention_2/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Post_Residual_id/br (None, 28, 28, 128)  512         Attention_2/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Post_Residual_id/br (None, 28, 28, 128)  0           Attention_2/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Post_Residual_id/br (None, 28, 28, 512)  66048       Attention_2/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_2/Post_Residual_id/Ad (None, 28, 28, 512)  0           Attention_2/Post_Residual_id/bran\n",
            "                                                                 Attention_2/Add[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_3/branch1/bn_1 (B (None, 28, 28, 512)  2048        Attention_2/Post_Residual_id/Add[\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_3/branch1/relu_1  (None, 28, 28, 512)  0           Residual_conv_3/branch1/bn_1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_3/branch1/conv_1  (None, 28, 28, 256)  131328      Residual_conv_3/branch1/relu_1[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_3/branch1/bn_2 (B (None, 28, 28, 256)  1024        Residual_conv_3/branch1/conv_1[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_3/branch1/relu_2  (None, 28, 28, 256)  0           Residual_conv_3/branch1/bn_2[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_3/branch1/conv_2  (None, 14, 14, 256)  590080      Residual_conv_3/branch1/relu_2[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_3/branch1/bn_3 (B (None, 14, 14, 256)  1024        Residual_conv_3/branch1/conv_2[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_3/branch2/bn_1 (B (None, 28, 28, 512)  2048        Attention_2/Post_Residual_id/Add[\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_3/branch1/relu_3  (None, 14, 14, 256)  0           Residual_conv_3/branch1/bn_3[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_3/branch2/relu_1  (None, 28, 28, 512)  0           Residual_conv_3/branch2/bn_1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_3/branch1/conv_3  (None, 14, 14, 1024) 263168      Residual_conv_3/branch1/relu_3[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_3/branch2/conv_1  (None, 14, 14, 1024) 525312      Residual_conv_3/branch2/relu_1[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_3/Add (Add)       (None, 14, 14, 1024) 0           Residual_conv_3/branch1/conv_3[0]\n",
            "                                                                 Residual_conv_3/branch2/conv_1[0]\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Pre_Residual_id/bra (None, 14, 14, 1024) 4096        Residual_conv_3/Add[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Pre_Residual_id/bra (None, 14, 14, 1024) 0           Attention_3/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Pre_Residual_id/bra (None, 14, 14, 256)  262400      Attention_3/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Pre_Residual_id/bra (None, 14, 14, 256)  1024        Attention_3/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Pre_Residual_id/bra (None, 14, 14, 256)  0           Attention_3/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Pre_Residual_id/bra (None, 14, 14, 256)  590080      Attention_3/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Pre_Residual_id/bra (None, 14, 14, 256)  1024        Attention_3/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Pre_Residual_id/bra (None, 14, 14, 256)  0           Attention_3/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Pre_Residual_id/bra (None, 14, 14, 1024) 263168      Attention_3/Pre_Residual_id/branc\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Pre_Residual_id/Add (None, 14, 14, 1024) 0           Attention_3/Pre_Residual_id/branc\n",
            "                                                                 Residual_conv_3/Add[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/pool_1 (MaxPoo (None, 7, 7, 1024)   0           Attention_3/Pre_Residual_id/Add[0\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Residual_id_1_ (None, 7, 7, 1024)   4096        Attention_3/Mask/pool_1[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Residual_id_1_ (None, 7, 7, 1024)   0           Attention_3/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Residual_id_1_ (None, 7, 7, 256)    262400      Attention_3/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Residual_id_1_ (None, 7, 7, 256)    1024        Attention_3/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Residual_id_1_ (None, 7, 7, 256)    0           Attention_3/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Residual_id_1_ (None, 7, 7, 256)    590080      Attention_3/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Residual_id_1_ (None, 7, 7, 256)    1024        Attention_3/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Residual_id_1_ (None, 7, 7, 256)    0           Attention_3/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Trunk/Residual_id_1 (None, 14, 14, 1024) 4096        Attention_3/Pre_Residual_id/Add[0\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Residual_id_1_ (None, 7, 7, 1024)   263168      Attention_3/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Trunk/Residual_id_1 (None, 14, 14, 1024) 0           Attention_3/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Residual_id_1_ (None, 7, 7, 1024)   0           Attention_3/Mask/Residual_id_1_Do\n",
            "                                                                 Attention_3/Mask/pool_1[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Trunk/Residual_id_1 (None, 14, 14, 256)  262400      Attention_3/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Residual_id_1_ (None, 7, 7, 1024)   4096        Attention_3/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Trunk/Residual_id_1 (None, 14, 14, 256)  1024        Attention_3/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Residual_id_1_ (None, 7, 7, 1024)   0           Attention_3/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Trunk/Residual_id_1 (None, 14, 14, 256)  0           Attention_3/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Residual_id_1_ (None, 7, 7, 256)    262400      Attention_3/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Trunk/Residual_id_1 (None, 14, 14, 256)  590080      Attention_3/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Residual_id_1_ (None, 7, 7, 256)    1024        Attention_3/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Trunk/Residual_id_1 (None, 14, 14, 256)  1024        Attention_3/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Residual_id_1_ (None, 7, 7, 256)    0           Attention_3/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Trunk/Residual_id_1 (None, 14, 14, 256)  0           Attention_3/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Residual_id_1_ (None, 7, 7, 256)    590080      Attention_3/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Trunk/Residual_id_1 (None, 14, 14, 1024) 263168      Attention_3/Trunk/Residual_id_1/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Residual_id_1_ (None, 7, 7, 256)    1024        Attention_3/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Trunk/Residual_id_1 (None, 14, 14, 1024) 0           Attention_3/Trunk/Residual_id_1/b\n",
            "                                                                 Attention_3/Pre_Residual_id/Add[0\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Residual_id_1_ (None, 7, 7, 256)    0           Attention_3/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Trunk/Residual_id_2 (None, 14, 14, 1024) 4096        Attention_3/Trunk/Residual_id_1/A\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Residual_id_1_ (None, 7, 7, 1024)   263168      Attention_3/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Trunk/Residual_id_2 (None, 14, 14, 1024) 0           Attention_3/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Residual_id_1_ (None, 7, 7, 1024)   0           Attention_3/Mask/Residual_id_1_Up\n",
            "                                                                 Attention_3/Mask/Residual_id_1_Do\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Trunk/Residual_id_2 (None, 14, 14, 256)  262400      Attention_3/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 14, 14, 1024) 0           Attention_3/Mask/Residual_id_1_Up\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Trunk/Residual_id_2 (None, 14, 14, 256)  1024        Attention_3/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Interpool_2/bn (None, 14, 14, 1024) 4096        lambda_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Trunk/Residual_id_2 (None, 14, 14, 256)  0           Attention_3/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Interpool_2/re (None, 14, 14, 1024) 0           Attention_3/Mask/Interpool_2/bn_1\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Trunk/Residual_id_2 (None, 14, 14, 256)  590080      Attention_3/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Interpool_2/co (None, 14, 14, 1024) 1049600     Attention_3/Mask/Interpool_2/relu\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Trunk/Residual_id_2 (None, 14, 14, 256)  1024        Attention_3/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Interpool_2/bn (None, 14, 14, 1024) 4096        Attention_3/Mask/Interpool_2/conv\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Trunk/Residual_id_2 (None, 14, 14, 256)  0           Attention_3/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Interpool_2/re (None, 14, 14, 1024) 0           Attention_3/Mask/Interpool_2/bn_2\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Trunk/Residual_id_2 (None, 14, 14, 1024) 263168      Attention_3/Trunk/Residual_id_2/b\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/Interpool_2/co (None, 14, 14, 1024) 1049600     Attention_3/Mask/Interpool_2/relu\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Trunk/Residual_id_2 (None, 14, 14, 1024) 0           Attention_3/Trunk/Residual_id_2/b\n",
            "                                                                 Attention_3/Trunk/Residual_id_1/A\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mask/sigmoid (Activ (None, 14, 14, 1024) 0           Attention_3/Mask/Interpool_2/conv\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Mutiply (Multiply)  (None, 14, 14, 1024) 0           Attention_3/Trunk/Residual_id_2/A\n",
            "                                                                 Attention_3/Mask/sigmoid[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Add (Add)           (None, 14, 14, 1024) 0           Attention_3/Trunk/Residual_id_2/A\n",
            "                                                                 Attention_3/Mutiply[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Post_Residual_id/br (None, 14, 14, 1024) 4096        Attention_3/Add[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Post_Residual_id/br (None, 14, 14, 1024) 0           Attention_3/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Post_Residual_id/br (None, 14, 14, 256)  262400      Attention_3/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Post_Residual_id/br (None, 14, 14, 256)  1024        Attention_3/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Post_Residual_id/br (None, 14, 14, 256)  0           Attention_3/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Post_Residual_id/br (None, 14, 14, 256)  590080      Attention_3/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Post_Residual_id/br (None, 14, 14, 256)  1024        Attention_3/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Post_Residual_id/br (None, 14, 14, 256)  0           Attention_3/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Post_Residual_id/br (None, 14, 14, 1024) 263168      Attention_3/Post_Residual_id/bran\n",
            "__________________________________________________________________________________________________\n",
            "Attention_3/Post_Residual_id/Ad (None, 14, 14, 1024) 0           Attention_3/Post_Residual_id/bran\n",
            "                                                                 Attention_3/Add[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_4/branch1/bn_1 (B (None, 14, 14, 1024) 4096        Attention_3/Post_Residual_id/Add[\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_4/branch1/relu_1  (None, 14, 14, 1024) 0           Residual_conv_4/branch1/bn_1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_4/branch1/conv_1  (None, 14, 14, 512)  524800      Residual_conv_4/branch1/relu_1[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_4/branch1/bn_2 (B (None, 14, 14, 512)  2048        Residual_conv_4/branch1/conv_1[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_4/branch1/relu_2  (None, 14, 14, 512)  0           Residual_conv_4/branch1/bn_2[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_4/branch1/conv_2  (None, 7, 7, 512)    2359808     Residual_conv_4/branch1/relu_2[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_4/branch1/bn_3 (B (None, 7, 7, 512)    2048        Residual_conv_4/branch1/conv_2[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_4/branch2/bn_1 (B (None, 14, 14, 1024) 4096        Attention_3/Post_Residual_id/Add[\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_4/branch1/relu_3  (None, 7, 7, 512)    0           Residual_conv_4/branch1/bn_3[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_4/branch2/relu_1  (None, 14, 14, 1024) 0           Residual_conv_4/branch2/bn_1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_4/branch1/conv_3  (None, 7, 7, 2048)   1050624     Residual_conv_4/branch1/relu_3[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_4/branch2/conv_1  (None, 7, 7, 2048)   2099200     Residual_conv_4/branch2/relu_1[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_conv_4/Add (Add)       (None, 7, 7, 2048)   0           Residual_conv_4/branch1/conv_3[0]\n",
            "                                                                 Residual_conv_4/branch2/conv_1[0]\n",
            "__________________________________________________________________________________________________\n",
            "Residual_id_1/branch1/bn_1 (Bat (None, 7, 7, 2048)   8192        Residual_conv_4/Add[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Residual_id_1/branch1/relu_1 (A (None, 7, 7, 2048)   0           Residual_id_1/branch1/bn_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Residual_id_1/branch1/conv_1 (C (None, 7, 7, 512)    1049088     Residual_id_1/branch1/relu_1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_id_1/branch1/bn_2 (Bat (None, 7, 7, 512)    2048        Residual_id_1/branch1/conv_1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_id_1/branch1/relu_2 (A (None, 7, 7, 512)    0           Residual_id_1/branch1/bn_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Residual_id_1/branch1/conv_2 (C (None, 7, 7, 512)    2359808     Residual_id_1/branch1/relu_2[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_id_1/branch1/bn_3 (Bat (None, 7, 7, 512)    2048        Residual_id_1/branch1/conv_2[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_id_1/branch1/relu_3 (A (None, 7, 7, 512)    0           Residual_id_1/branch1/bn_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Residual_id_1/branch1/conv_3 (C (None, 7, 7, 2048)   1050624     Residual_id_1/branch1/relu_3[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_id_1/Add (Add)         (None, 7, 7, 2048)   0           Residual_id_1/branch1/conv_3[0][0\n",
            "                                                                 Residual_conv_4/Add[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Residual_id_2/branch1/bn_1 (Bat (None, 7, 7, 2048)   8192        Residual_id_1/Add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Residual_id_2/branch1/relu_1 (A (None, 7, 7, 2048)   0           Residual_id_2/branch1/bn_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Residual_id_2/branch1/conv_1 (C (None, 7, 7, 512)    1049088     Residual_id_2/branch1/relu_1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_id_2/branch1/bn_2 (Bat (None, 7, 7, 512)    2048        Residual_id_2/branch1/conv_1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_id_2/branch1/relu_2 (A (None, 7, 7, 512)    0           Residual_id_2/branch1/bn_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Residual_id_2/branch1/conv_2 (C (None, 7, 7, 512)    2359808     Residual_id_2/branch1/relu_2[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_id_2/branch1/bn_3 (Bat (None, 7, 7, 512)    2048        Residual_id_2/branch1/conv_2[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_id_2/branch1/relu_3 (A (None, 7, 7, 512)    0           Residual_id_2/branch1/bn_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Residual_id_2/branch1/conv_3 (C (None, 7, 7, 2048)   1050624     Residual_id_2/branch1/relu_3[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Residual_id_2/Add (Add)         (None, 7, 7, 2048)   0           Residual_id_2/branch1/conv_3[0][0\n",
            "                                                                 Residual_id_1/Add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "bn_2 (BatchNormalization)       (None, 7, 7, 2048)   8192        Residual_id_2/Add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "relu_2 (Activation)             (None, 7, 7, 2048)   0           bn_2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           relu_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Dense_1 (Dense)                 (None, 2)            4098        flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "classifier (Activation)         (None, 2)            0           Dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 29,886,082\n",
            "Trainable params: 29,809,666\n",
            "Non-trainable params: 76,416\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hUuQ3DGhBeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYXxxyZHbQC2",
        "colab_type": "code",
        "outputId": "48a71721-8b2b-4efb-8e2a-f8e73a1a4adc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "train_datagen = image.ImageDataGenerator(rotation_range=40, width_shift_range=0.2, height_shift_range=0.2,\n",
        "                                        shear_range=0.2, zoom_range=0.2, horizontal_flip=True,\n",
        "                                        fill_mode='nearest', rescale=1/255)\n",
        "val_datagen = image.ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "batch_size = 32\n",
        "train_generator = train_datagen.flow_from_directory('image/train', target_size=(224,224),batch_size=batch_size)\n",
        "val_generator = val_datagen.flow_from_directory('image/test', target_size=(224,224), batch_size=batch_size)\n",
        "\n",
        "earlystopping = EarlyStopping(monitor='val_loss', patience=9, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1,\n",
        "                              factor=0.2,\n",
        "                             min_delta=0.0001, min_lr=1e-7, mode='auto')\n",
        "\n",
        "print(train_generator.class_indices)\n",
        "\n",
        "model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit_generator(train_generator, steps_per_epoch=len(train_generator), epochs=300,\n",
        "                   validation_data=val_generator, validation_steps=len(val_generator),\n",
        "                   callbacks=[earlystopping, reduce_lr])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n",
            "{'cat': 0, 'dog': 1}\n",
            "Epoch 1/300\n",
            "13/13 [==============================] - 63s 5s/step - loss: 0.4896 - acc: 0.7810 - val_loss: 1.8950 - val_acc: 0.5050\n",
            "Epoch 2/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.5083 - acc: 0.7574 - val_loss: 4.7691 - val_acc: 0.5200\n",
            "Epoch 3/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.5022 - acc: 0.7574 - val_loss: 3.2829 - val_acc: 0.5100\n",
            "Epoch 4/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.5987 - acc: 0.7240 - val_loss: 2.5057 - val_acc: 0.4050\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "Epoch 5/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.4581 - acc: 0.7930 - val_loss: 1.1986 - val_acc: 0.4650\n",
            "Epoch 6/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.4309 - acc: 0.7882 - val_loss: 1.1718 - val_acc: 0.5150\n",
            "Epoch 7/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.3875 - acc: 0.8079 - val_loss: 1.4144 - val_acc: 0.5350\n",
            "Epoch 8/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.3999 - acc: 0.8003 - val_loss: 1.0867 - val_acc: 0.5600\n",
            "Epoch 9/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.3773 - acc: 0.8103 - val_loss: 1.3182 - val_acc: 0.5700\n",
            "Epoch 10/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.4058 - acc: 0.8149 - val_loss: 1.1572 - val_acc: 0.5950\n",
            "Epoch 11/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.3699 - acc: 0.8511 - val_loss: 1.0217 - val_acc: 0.6200\n",
            "Epoch 12/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.3446 - acc: 0.8463 - val_loss: 0.9657 - val_acc: 0.6200\n",
            "Epoch 13/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.3356 - acc: 0.8342 - val_loss: 0.9598 - val_acc: 0.6400\n",
            "Epoch 14/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.3303 - acc: 0.8750 - val_loss: 1.0836 - val_acc: 0.6300\n",
            "Epoch 15/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.3400 - acc: 0.8438 - val_loss: 1.2707 - val_acc: 0.6450\n",
            "Epoch 16/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.3344 - acc: 0.8507 - val_loss: 1.0880 - val_acc: 0.6400\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
            "Epoch 17/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.2944 - acc: 0.8796 - val_loss: 1.0615 - val_acc: 0.6300\n",
            "Epoch 18/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.3049 - acc: 0.8579 - val_loss: 1.0161 - val_acc: 0.6200\n",
            "Epoch 19/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.3061 - acc: 0.8678 - val_loss: 1.0083 - val_acc: 0.6300\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
            "Epoch 20/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.3095 - acc: 0.8676 - val_loss: 0.9933 - val_acc: 0.6350\n",
            "Epoch 21/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.2984 - acc: 0.8796 - val_loss: 0.9665 - val_acc: 0.6250\n",
            "Epoch 22/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.2708 - acc: 0.8921 - val_loss: 0.9510 - val_acc: 0.6350\n",
            "Epoch 23/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.3236 - acc: 0.8705 - val_loss: 0.9440 - val_acc: 0.6200\n",
            "Epoch 24/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.2999 - acc: 0.8845 - val_loss: 0.9377 - val_acc: 0.6200\n",
            "Epoch 25/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.2641 - acc: 0.8871 - val_loss: 0.9275 - val_acc: 0.6150\n",
            "Epoch 26/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.3307 - acc: 0.8700 - val_loss: 0.9218 - val_acc: 0.6150\n",
            "Epoch 27/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.2822 - acc: 0.8846 - val_loss: 0.9168 - val_acc: 0.6150\n",
            "Epoch 28/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.3135 - acc: 0.8583 - val_loss: 0.9111 - val_acc: 0.6250\n",
            "Epoch 29/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.2971 - acc: 0.8845 - val_loss: 0.9111 - val_acc: 0.6400\n",
            "Epoch 30/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.3128 - acc: 0.8494 - val_loss: 0.9059 - val_acc: 0.6350\n",
            "Epoch 31/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.2947 - acc: 0.8676 - val_loss: 0.9043 - val_acc: 0.6350\n",
            "Epoch 32/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.2976 - acc: 0.8607 - val_loss: 0.9044 - val_acc: 0.6200\n",
            "Epoch 33/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.3099 - acc: 0.8631 - val_loss: 0.9070 - val_acc: 0.6300\n",
            "Epoch 34/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.2989 - acc: 0.8559 - val_loss: 0.9081 - val_acc: 0.6300\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
            "Epoch 35/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.2817 - acc: 0.8846 - val_loss: 0.9081 - val_acc: 0.6300\n",
            "Epoch 36/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.2917 - acc: 0.8822 - val_loss: 0.9101 - val_acc: 0.6300\n",
            "Epoch 37/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.3128 - acc: 0.8798 - val_loss: 0.9116 - val_acc: 0.6300\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "Epoch 38/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.2951 - acc: 0.8774 - val_loss: 0.9151 - val_acc: 0.6300\n",
            "Epoch 39/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.2747 - acc: 0.8826 - val_loss: 0.9166 - val_acc: 0.6300\n",
            "Epoch 40/300\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.2797 - acc: 0.8772 - val_loss: 0.9166 - val_acc: 0.6300\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "Epoch 00040: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8eff61afd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGVLc_V7eAoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}