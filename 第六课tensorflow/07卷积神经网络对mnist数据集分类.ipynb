{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "p1M39C0Ey2e0",
    "outputId": "7e76c698-67e5-4728-bb78-d7e49a7c70d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nvhdZnKqyws_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('drive/My Drive/Colab Notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sGROFjP6zEJ0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "Um2N1gL8zIwo",
    "outputId": "8945ad4d-7413-4092-b36a-5707687a1332"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0825 03:25:01.059711 140037632825216 deprecation.py:323] From <ipython-input-4-117f2a6e5922>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0825 03:25:01.062004 140037632825216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0825 03:25:01.063943 140037632825216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0825 03:25:02.036031 140037632825216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0825 03:25:02.362365 140037632825216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0825 03:25:02.871690 140037632825216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "batch_size = 64\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "# print(n_batch, mnist.train.num_examples)    # 859 55000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "id": "w-Uge9WvzUhZ",
    "outputId": "dfc21eec-9dab-4509-b19b-b1439e774911"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0825 03:25:22.233190 140037632825216 deprecation.py:506] From <ipython-input-5-c7adb59f2258>:61: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0825 03:25:22.308038 140037632825216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, test accuracy is 0.8664000034332275\n",
      "Epoch 1, test accuracy is 0.8790000081062317\n",
      "Epoch 2, test accuracy is 0.9739000201225281\n",
      "Epoch 3, test accuracy is 0.9794999957084656\n",
      "Epoch 4, test accuracy is 0.9783999919891357\n",
      "Epoch 5, test accuracy is 0.9846000075340271\n",
      "Epoch 6, test accuracy is 0.982200026512146\n",
      "Epoch 7, test accuracy is 0.9869999885559082\n",
      "Epoch 8, test accuracy is 0.9866999983787537\n",
      "Epoch 9, test accuracy is 0.9883999824523926\n",
      "Epoch 10, test accuracy is 0.9887999892234802\n",
      "Epoch 11, test accuracy is 0.9890000224113464\n",
      "Epoch 12, test accuracy is 0.9896000027656555\n",
      "Epoch 13, test accuracy is 0.9872999787330627\n",
      "Epoch 14, test accuracy is 0.9905999898910522\n",
      "Epoch 15, test accuracy is 0.9876000285148621\n",
      "Epoch 16, test accuracy is 0.9869999885559082\n",
      "Epoch 17, test accuracy is 0.9898999929428101\n",
      "Epoch 18, test accuracy is 0.9900000095367432\n",
      "Epoch 19, test accuracy is 0.9894000291824341\n",
      "Epoch 20, test accuracy is 0.991100013256073\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 初始化权值\n",
    "def weight_variable(shape):\n",
    "    w = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(w)\n",
    "\n",
    "# 初始化bias\n",
    "def bias_variable(shape):\n",
    "    bias = tf.zeros(shape) + 0.1\n",
    "    return tf.Variable(bias)\n",
    "\n",
    "# 卷积层\n",
    "def conv2d(x, w):\n",
    "    '''\n",
    "    tf.nn.con2d(): \n",
    "    w = filter: [k_height, k_width, in_channel, out_channel]\n",
    "    strides: [1, x_strides, y_strides, 1] 两端固定为1，x_strides为x方向的步长，y_strides为y方向的步长 \n",
    "    '''\n",
    "    return tf.nn.conv2d(x, filter=w, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "# 池化层\n",
    "def max_pool_2x2(x):\n",
    "    '''\n",
    "    ksize: [1, x , y, 1]\n",
    "    '''\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "# 建立一个网络框架\n",
    "## input[batch, in_height, in_width, in_channels] ----> conv1[batch, 28, 28, out_channels1 ]\n",
    "## ----> pooling1[batch, 14, 14, out_channels1] ----> conv2[ ] ---->pooling2[ ]\n",
    "\n",
    "# 把x转换为4维格式\n",
    "x_image = tf.reshape(x, [-1,28,28,1])    # -1会自动匹配上批次的大小，因为CNN要求传入4维的数据\n",
    "\n",
    "# 初始化第一层的权重和偏置\n",
    "w_conv1 = weight_variable([5,5,1,32])    # 5*5的kernel，输入通道数是1，输出通道数是32\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "# 把x_image和权值向量进行卷积，再加上bias，然后使用relu激活函数，最后池化，完成第一层\n",
    "a_conv1 = tf.nn.relu(conv2d(x_image, w_conv1)+b_conv1)\n",
    "a_pool1 = max_pool_2x2(a_conv1)\n",
    "\n",
    "# 初始化第二层的权重和偏置\n",
    "w_conv2 = weight_variable([5,5,32,64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "a_conv2 = tf.nn.relu(conv2d(a_pool1, w_conv2)+b_conv2)\n",
    "a_pool2 = max_pool_2x2(a_conv2)\n",
    "## [64,7,7,64] 得到64个7*7*64的数据\n",
    "## 把a_pool2扁平化处理，以便后续全连接层使用\n",
    "a_pool2_flat = tf.reshape(a_pool2, shape=[-1, 7*7*64])\n",
    "\n",
    "# 初始化第一个全连接层的权重和偏置\n",
    "w_fc1 = weight_variable([7*7*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "a_fc1 = tf.nn.relu(tf.matmul(a_pool2_flat, w_fc1)+b_fc1)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "a_fc1_drop = tf.nn.dropout(a_fc1, keep_prob)\n",
    "\n",
    "# 初始化第二个全连接层\n",
    "w_fc2 = weight_variable([1024,10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "pred = tf.nn.softmax(tf.matmul(a_fc1_drop, w_fc2)+b_fc2)\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(y, pred)\n",
    "train = tf.train.AdamOptimizer(0.0001).minimize(loss)\n",
    "\n",
    "corret_pred = tf.equal(tf.argmax(y,1), tf.argmax(pred,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(corret_pred, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train, feed_dict={x:batch_xs, y:batch_ys, keep_prob:1.0})\n",
    "#             print('{}-{}'.format(epoch, batch),end=' ')\n",
    "        acc = sess.run(accuracy, feed_dict={x:mnist.test.images, y:mnist.test.labels, keep_prob:1.0})\n",
    "        print('Epoch {}, test accuracy is {}'.format(epoch,acc))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "07卷积神经网络对mnist数据集分类.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
