{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jk6GyosSI5Xf"
   },
   "source": [
    "#### 说明\n",
    "虽然“交叉熵+dropout”和“交叉熵+正则化”的效果不如“仅使用交叉熵”的，但关键在于如何使用这些优化方法，不同的案例效果可能不同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 目录\n",
    "1. 仅使用交叉熵\n",
    "2. 交叉熵+dropout\n",
    "3. 交叉熵+正则化\n",
    "4. 交叉熵+Adam优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sJhuZd0BEM5q"
   },
   "source": [
    "#### 仅使用交叉熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YoTlQfS98aAZ",
    "outputId": "b1d5cab8-e31a-4250-edbf-f8dcb4c757a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "id": "VLIgm5sr8qF2",
    "outputId": "ee4f2747-03ef-4bb3-ea13-179a6093027f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/10\n",
      " 1088/60000 [..............................] - ETA: 7:35 - loss: 1.0751 - acc: 0.6480 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.111375). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 17s 286us/step - loss: 0.2510 - acc: 0.9236\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.1121 - acc: 0.9656\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0768 - acc: 0.9758\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0567 - acc: 0.9822\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.0445 - acc: 0.9856\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0317 - acc: 0.9899\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0225 - acc: 0.9931\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0153 - acc: 0.9958\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.0093 - acc: 0.9977\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0052 - acc: 0.9991\n",
      "10000/10000 [==============================] - 1s 86us/step\n",
      "loss 0.0691565755004398\n",
      "accuracy 0.9809\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)/255.0\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)/255.0\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# 建立模型 784 ---》200 ---》100 ---》10\n",
    "###################################第一种：仅使用交叉熵#############################################\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(units=200, input_dim=784, activation='tanh',name='layer1'))\n",
    "model.add(Dense(units=100, input_dim=200, activation='tanh',name='layer2'))\n",
    "model.add(Dense(units=10, input_dim=100,activation='softmax',name='output'))\n",
    "\n",
    "sgd = SGD(lr=0.3)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('loss', loss)\n",
    "print('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HREhxRMLC76P"
   },
   "source": [
    "#### 交叉熵+dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9PU6c3SUC7aI"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "colab_type": "code",
    "id": "t_3yV7ns8sY6",
    "outputId": "e6aaa84d-2220-4cf7-f1ff-3019a23d6142"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.3052 - acc: 0.9077\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.1707 - acc: 0.9486\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.1329 - acc: 0.9589\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.1140 - acc: 0.9653\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.1047 - acc: 0.9675\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0909 - acc: 0.9718\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0825 - acc: 0.9742\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0754 - acc: 0.9756\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.0719 - acc: 0.9775\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.0684 - acc: 0.9785\n",
      "10000/10000 [==============================] - 1s 65us/step\n",
      "test loss 0.07573686599871143 test accuracy 0.9783\n"
     ]
    }
   ],
   "source": [
    "################################## 第二种方法：交叉熵 + dropout #########################################\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)/255.0\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)/255.0\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# 784 ---> 200 ---> 100 ---> 10\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(units=200, input_dim=784, activation='tanh', name='layer1'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(units=100, activation='tanh', name='layer2'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(units=10, activation='softmax', name='output0'))\n",
    "sgd = SGD(lr=0.3)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print('test loss', loss, 'test accuracy', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ETRHqHPHsen"
   },
   "source": [
    "#### 交叉熵 + 正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2zFBY85kDnrr",
    "outputId": "82bf3ab0-7ac8-49d9-910b-930246eadddb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "xaMZWyn7HxYe",
    "outputId": "4c75e6e2-a2ab-49b5-e318-5cd308287728"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.3903 - acc: 0.9213\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.2429 - acc: 0.9582\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.2033 - acc: 0.9669\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.1817 - acc: 0.9702\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.1750 - acc: 0.9713\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.1677 - acc: 0.9729\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.1627 - acc: 0.9745\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.1642 - acc: 0.9739\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.1618 - acc: 0.9746\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.1587 - acc: 0.9764\n",
      "10000/10000 [==============================] - 1s 70us/step\n",
      "test loss is 0.18946782796382905 test accuracy is 0.9668\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], -1) / 255.0\n",
    "x_test = x_test.reshape(x_test.shape[0], -1) / 255.0\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# 784 200 100 10\n",
    "model = Sequential()\n",
    "model.add(Dense(units=200, input_dim=784, activation='tanh', kernel_regularizer=l2(0.0003), name='layer_1'))\n",
    "model.add(Dense(units=100, activation='tanh', kernel_regularizer=l2(0.0003), name='layer_2'))\n",
    "model.add(Dense(units=10, activation='softmax', name='output_0'))\n",
    "sgd = SGD(lr=0.3)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('test loss is',loss, 'test accuracy is', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jPBV422oMZt9"
   },
   "source": [
    "#### 交叉熵+Adam优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5gVKM57_H07A"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "Ut0eiYIGMexk",
    "outputId": "e976d76b-b89e-4425-8d94-0ec647fe9f0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.2444 - acc: 0.9277\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.1126 - acc: 0.9656\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.0774 - acc: 0.9763\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0553 - acc: 0.9825\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.0422 - acc: 0.9866\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0318 - acc: 0.9902\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.0261 - acc: 0.9915\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0188 - acc: 0.9942\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0182 - acc: 0.9943\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0159 - acc: 0.9950\n",
      "10000/10000 [==============================] - 1s 67us/step\n",
      "test loss is 0.08933973452044301 test accuracy is 0.9749\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], -1) / 255.0\n",
    "x_test = x_test.reshape(x_test.shape[0], -1) / 255.0\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=200, input_dim=784, activation='tanh', name='layer_0'))\n",
    "model.add(Dense(units=100, activation='tanh', name='layer_1'))\n",
    "model.add(Dense(units=10, activation='softmax', name='output_0'))\n",
    "adam = Adam(lr=0.001)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print('test loss is',loss, 'test accuracy is', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bnKf_zuvNt5T"
   },
   "source": [
    "看上去似乎存在一点过拟合，因为训练集的acc比测试集的大的相对对一点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvWiRXniMguw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "03_mnist数据集优化(交叉熵_正则化_优化器的选择).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
